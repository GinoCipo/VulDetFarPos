{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392da7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import myutils\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#default mode / type of vulnerability\n",
    "mode = \"path_disclosure\"\n",
    "\n",
    "#get the vulnerability from the command line argument\n",
    "if (len(sys.argv) > 1):\n",
    "  mode = sys.argv[1]\n",
    "\n",
    "model = load_model('Model-BiLSTM/Bidirectional_LSTM_model_path_disclosure.h5',custom_objects={'f1_loss': myutils.f1_loss, 'f1':myutils.f1})\n",
    "  \n",
    "\n",
    "with open('data/path_disclosure_dataset_finaltest_X', 'rb') as fp:\n",
    "  FinaltestX = pickle.load(fp)\n",
    "with open('data/path_disclosure_dataset_finaltest_Y', 'rb') as fp:\n",
    "  FinaltestY = pickle.load(fp)\n",
    "\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "nowformat = now.strftime(\"%H:%M\")\n",
    "\n",
    "#Prepare the data for the LSTM model\n",
    "\n",
    "\n",
    "y_finaltest =  numpy.array(FinaltestY, dtype=\"object\")\n",
    "X_finaltest =  numpy.array(FinaltestX, dtype=\"object\")\n",
    "\n",
    "#in the original collection of data, the 0 and 1 were used the other way round, so now they are switched so that \"1\" means vulnerable and \"0\" means clean.\n",
    "    \n",
    "for i in range(len(y_finaltest)):\n",
    "  if y_finaltest[i] == 0:\n",
    "    y_finaltest[i] = 1\n",
    "  else:\n",
    "    y_finaltest[i] = 0\n",
    "\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "nowformat = now.strftime(\"%H:%M\")\n",
    "\n",
    "print(str(len(X_finaltest)) + \" samples in the final test set.\")\n",
    "  \n",
    "  \n",
    "csum = 0\n",
    "for y in y_finaltest:\n",
    "  csum = csum+y\n",
    "\n",
    "print(\"percentage of vulnerable samples: \"  + str(int((csum / len(X_finaltest)) * 10000)/100) + \"%\")\n",
    "print(\"absolute amount of vulnerable samples in test set: \" + str(csum))\n",
    "\n",
    "#padding sequences on the same length\n",
    "max_length = 200   \n",
    "X_finaltest = sequence.pad_sequences(X_finaltest, maxlen=max_length)\n",
    "\n",
    "X_finaltest = numpy.asarray(X_finaltest).astype(numpy.float32)\n",
    "y_finaltest= numpy.asarray(y_finaltest).astype(numpy.float32)     \n",
    "      \n",
    "yhat_classes = (model.predict(X_finaltest) > 0.5).astype(\"int32\")\n",
    "accuracy = accuracy_score(y_finaltest, yhat_classes)\n",
    "precision = precision_score(y_finaltest, yhat_classes)\n",
    "recall = recall_score(y_finaltest, yhat_classes)\n",
    "F1Score = f1_score(y_finaltest, yhat_classes)\n",
    "  \n",
    "print(\"Accuracy-BiLSTM: \" + str(accuracy))\n",
    "print(\"Precision-BiLSTM: \" + str(precision))\n",
    "print(\"Recall-BiLSTM: \" + str(recall))\n",
    "print('F1 score-BiLSTM: %f' % F1Score)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#lstmauc\n",
    "y_pred_lstm = model.predict(X_finaltest).ravel()\n",
    "fpr_lstm, tpr_lstm, thresholds_lstm = roc_curve(y_finaltest, y_pred_lstm)\n",
    "auc_lstm = auc(fpr_lstm, tpr_lstm)\n",
    "print (auc_lstm)\n",
    "\n",
    "\n",
    "\n",
    "#setshape\n",
    "nsamples, nx, ny = X_finaltest.shape\n",
    "X_finaltest = X_finaltest.reshape((nsamples,nx*ny))\n",
    "\n",
    "\n",
    "\n",
    "#load-LR\n",
    "import pickle\n",
    "pickled_model = pickle.load(open('path-LR.pkl', 'rb'))\n",
    "lg_probs = pickled_model.predict(X_finaltest)\n",
    "accuracylg = accuracy_score(y_finaltest, lg_probs)\n",
    "print('Accuracy-LR: %f' % accuracylg)\n",
    "# precision tp / (tp + fp)\n",
    "precisionlg = precision_score(y_finaltest, lg_probs)\n",
    "print('Precision-LR: %f' % precisionlg)\n",
    "# recall: tp / (tp + fn)\n",
    "recalllg = recall_score(y_finaltest, lg_probs)\n",
    "print('Recall-LR: %f' % recalllg)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1lg = f1_score(y_finaltest, lg_probs)\n",
    "print('F1 score-LR: %f' % f1lg)\n",
    "\n",
    "#auc-LR\n",
    "y_pred_lr = pickled_model.predict_proba(X_finaltest)[:, 1]\n",
    "fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_finaltest, y_pred_lr)\n",
    "auc_lr = auc(fpr_lr, tpr_lr)\n",
    "print (fpr_lr)\n",
    "\n",
    "\n",
    "#load-GNB\n",
    "pickled_model2 = pickle.load(open('path-GNB.pkl', 'rb'))\n",
    "G_probs = pickled_model2.predict(X_finaltest)\n",
    "accuracyGNB = accuracy_score(y_finaltest, G_probs)\n",
    "print('Accuracy-GNB: %f' % accuracyGNB)\n",
    "# precision tp / (tp + fp)\n",
    "precisionGNB = precision_score(y_finaltest, G_probs)\n",
    "print('Precision-GNB: %f' % precisionGNB)\n",
    "# recall: tp / (tp + fn)\n",
    "recallGNB = recall_score(y_finaltest, G_probs)\n",
    "print('Recall-GNB: %f' % recallGNB)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1GNB = f1_score(y_finaltest, G_probs)\n",
    "print('F1 score-GNB: %f' % f1GNB)   \n",
    "\n",
    "\n",
    "\n",
    "#auc-GNB\n",
    "y_pred_GNB = pickled_model2.predict_proba(X_finaltest)[:, 1]\n",
    "fpr_gnb, tpr_gnb, thresholds_gnb = roc_curve(y_finaltest, y_pred_GNB)\n",
    "auc_gnb = auc(fpr_gnb, tpr_gnb)\n",
    "print (fpr_gnb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#load-MLP\n",
    "pickled_model3 = pickle.load(open('path-MLP.pkl', 'rb'))\n",
    "m_probs = pickled_model3.predict(X_finaltest)\n",
    "accuracymlp = accuracy_score(y_finaltest, m_probs)\n",
    "print('Accuracy-MLP: %f' % accuracymlp)\n",
    "# precision tp / (tp + fp)\n",
    "precisionmlp = precision_score(y_finaltest, m_probs)\n",
    "print('Precision-MLP: %f' % precisionmlp)\n",
    "# recall: tp / (tp + fn)\n",
    "recallmlp = recall_score(y_finaltest, m_probs)\n",
    "print('Recall-MLP: %f' % recallmlp)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1mlp = f1_score(y_finaltest, m_probs)\n",
    "print('F1 score-MLP: %f' % f1mlp)  \n",
    "\n",
    "#auc-MLP\n",
    "y_pred_mlp = pickled_model3.predict_proba(X_finaltest)[:, 1]\n",
    "fpr_mlp, tpr_mlp, thresholds_mlp = roc_curve(y_finaltest, y_pred_mlp)\n",
    "auc_mlp = auc(fpr_mlp, tpr_mlp)\n",
    "print (fpr_mlp)\n",
    "\n",
    "max_length = 10000   \n",
    "X_finaltest = sequence.pad_sequences(X_finaltest, maxlen=max_length)\n",
    "\n",
    "X_finaltest = numpy.asarray(X_finaltest).astype(numpy.float32)\n",
    "y_finaltest= numpy.asarray(y_finaltest).astype(numpy.float32) \n",
    "\n",
    "#load-TREE\n",
    "pickled_model4 = pickle.load(open('path-TREE.pkl', 'rb'))\n",
    "treehat_probs = pickled_model4.predict(X_finaltest)\n",
    "accuracy = accuracy_score(y_finaltest, treehat_probs)\n",
    "print('Accuracy-tree: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_finaltest, treehat_probs)\n",
    "print('Precision-tree: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_finaltest, treehat_probs)\n",
    "print('Recall-tree: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(y_finaltest, treehat_probs)\n",
    "print('F1 score-tree: %f' % f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#auc-TREE\n",
    "probs = pickled_model4.predict_proba(X_finaltest)\n",
    "probs = probs[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_finaltest, probs)\n",
    "auc_tree = auc(fpr,tpr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ploting F-score\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=3.0)\n",
    "plt.plot(fpr_lstm, tpr_lstm, label='BiLSTM (area = {:.3f})'.format(auc_lstm), linewidth=3.5)\n",
    "plt.plot(fpr_lr, tpr_lr, label='LR (area = {:.3f})'.format(auc_lr), linewidth=3.5)\n",
    "plt.plot(fpr_gnb, tpr_gnb, label='GNB (area = {:.3f})'.format(auc_gnb), linewidth=2.5)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label='MLP (area = {:.3f})'.format(auc_mlp), linewidth=3.5)\n",
    "plt.plot(fpr, tpr, label='Decision Tree (area = {:.3f})'.format(auc_tree), linewidth=3.5)\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=18, weight = 'bold')\n",
    "plt.ylabel('True positive rate', fontsize=20, weight = 'bold')\n",
    "plt.title('ROC curve',fontsize=18, weight = 'bold')\n",
    "plt.legend(loc='best')\n",
    "plt.xticks(weight = 'bold')\n",
    "plt.yticks(weight = 'bold')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
